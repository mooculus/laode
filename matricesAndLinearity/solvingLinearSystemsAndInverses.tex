\documentclass{ximera}

\input{../preamble.tex}

\title{Solving Linear Systems and Inverses}

\begin{document}
\begin{abstract}
\end{abstract}
\maketitle

 \label{S:SLS}

When we solve the simple equation
\[
ax=b,
\]
we do so by dividing by $a$ to obtain
\[
x=\frac{1}{a}b.
\]
This division works as long as $a\neq 0$.

Writing systems of linear equations as
\[
Ax=b
\]
suggests that solutions should have the form
\[
x=\frac{1}{A} b
\]
and the \Matlab command for solving linear systems
\begin{verbatim}
x=A\b
\end{verbatim}
suggests that there is some merit to this analogy.

The following is a better analogy.  Multiplication by $a$ has the
inverse operation: division by $a$; multiplying a number $x$ by
$a$ and then multiplying the result by $a\inv=1/a$ leaves the number
$x$ unchanged (as long as $a\neq 0$).  In this sense we should
write the solution to $ax=b$ as
\[
x=a\inv b.
\]
For systems of equations $Ax=b$ we wish to write solutions as
\[
x=A\inv b.
\]
In this section we consider the questions: What does $A\inv$
mean and when does $A\inv$ exist? (Even in one dimension, we
have seen that the inverse does not always exist, since
$0\inv=\frac{1}{0}$ is undefined.)

\subsection*{Invertibility}

We begin by giving a precise definition of invertibility for square matrices.
\begin{definition} \label{inverse} \index{inverse} \index{invertible}
The $n\times n$ matrix $A$ is {\em invertible\/} if there is an $n\times n$
matrix $B$ such that
\[
AB=I_n \AND BA=I_n.
\]
The matrix $B$ is called an {\em inverse\/} of $A$.  If $A$ is not invertible,
then $A$ is {\em noninvertible\/} or {\em singular\/}. \index{noninvertible}
\index{singular}
\end{definition}

Geometrically, we can see that some matrices are invertible.  For example, 
the matrix
\[
R_{90} = \mattwo{0}{-1}{1}{0}
\]
rotates the plane counterclockwise through $90^\circ$ and is
invertible.  The inverse matrix of $R_{90}$ is the matrix that rotates the
plane clockwise through $90^\circ$.  That matrix is:
\[
R_{-90} = \mattwo{0}{1}{-1}{0}.
\]
This statement can be checked algebraically by verifying that 
$R_{90}R_{-90}=I_2$ and that $R_{-90}R_{90} = I_2$.

Similarly,  
\[
B = \mattwo{5}{3}{2}{1}
\]
is an inverse of 
\[
A = \mattwo{-1}{3}{2}{-5},
\]
as matrix multiplication shows that $AB=I_2$ and $BA=I_2$. In fact, there is 
an elementary formula for finding inverses of $2\times 2$ matrices (when they 
exist); see \eqref{e:formAinv} in Section~\ref{S:det2x2}.

On the other hand, not all matrices are invertible.  For example, the zero 
matrix is noninvertible, since $0B=0$ for any matrix $B$.

\begin{lemma} \label{B=C}
If an $n\times n$ matrix $A$ is invertible, then its inverse is unique
and is denoted by $A\inv$.
\end{lemma}

\begin{proof}
Let $B$ and $C$ be $n\times n$ matrices that are inverses of $A$.  Then
\[
BA=I_n \AND AC=I_n.
\]
We use the associativity of matrix multiplication to
prove that $B=C$.  Compute
\[
B = BI_n = B(AC) = (BA)C = I_nC = C.
\]
\end{proof}

We now show how to compute inverses for products of invertible
matrices.

\begin{proposition} \label{P:invprod} \index{matrix!multiplication}
\index{inverse}
Let $A$ and $B$ be two invertible $n\times n$ matrices.  Then
$AB$ is also invertible and
\[
(AB)\inv = B\inv A\inv.
\]
\end{proposition}

\begin{proof}  Use associativity of matrix multiplication to compute
\[
(AB)(B\inv A\inv) = A(BB\inv)A\inv = AI_nA\inv = AA\inv=I_n.
\]
Similarly,
\[
(B\inv A\inv)(AB) = B\inv(A\inv A)B = B\inv B = I_n.
\]
Therefore $AB$ is invertible with the desired inverse. \end{proof}

\begin{proposition} \label{L:transposeinv} \index{matrix!transpose}
Suppose that $A$ is an invertible $n\times n$ matrix.  Then
$A^t$ is invertible and
\[
(A^t)\inv = (A\inv)^t.
\]
\end{proposition}

\begin{proof}  We must show that $(A\inv)^t$ is the inverse of $A^t$.  Identity
\eqref{e:transposeprod} implies that
\[
(A\inv)^tA^t = (AA\inv)^t = (I_n)^t = I_n,
\]
and
\[
A^t(A\inv)^t = (A\inv A)^t = (I_n)^t = I_n.
\]
Therefore, $(A\inv)^t$ is the inverse of $A^t$, as claimed.  \end{proof}

\subsection*{Invertibility and Unique Solutions}

Next we discuss the implications of invertibility for the
solution of the inhomogeneous linear system:  \index{inhomogeneous}
\begin{equation}  \label{squarematrix}
Ax=b,
\end{equation}
where $A$ is an $n\times n$ matrix and $b\in\R^n$.

\begin{proposition} \label{P:inv=>unique}\index{uniqueness of solutions}
Let $A$ be an invertible $n\times n$ matrix and let $b$ be in $\R^n$.
Then the system of linear equations \eqref{squarematrix} has a unique solution.
\end{proposition}

\begin{proof}  We can solve the linear system \eqref{squarematrix} by setting
\begin{equation}  \label{soln}
x=A\inv b.
\end{equation}
This solution is easily verified by calculating
\[
Ax=A(A\inv b) = (AA\inv)b = I_nb = b.
\]
Next, suppose that $x$ is a solution to \eqref{squarematrix}.  Then
\[
x = I_n x = (A\inv A)x = A\inv(Ax) = A\inv b.
\]
So $A\inv b$ is the only possible solution.  \end{proof}

\begin{corollary} \label{C:inv=>In}
An invertible matrix is row equivalent to $I_n$.
\end{corollary}

\begin{proof}  Let $A$ be an invertible $n\times n$ matrix.
Proposition~\ref{P:inv=>unique} states that the system of linear equations
$Ax=b$ has a unique solution.  Chapter~\ref{lineq}, Corollary~\ref{consistent}
states that $A$ is row equivalent to $I_n$.  \end{proof}

The converse of Corollary~\ref{C:inv=>In} is also valid.

\begin{proposition}  \label{P:row=>inv}
An $n\times n$ matrix $A$ that is row equivalent to $I_n$ is invertible.
\end{proposition}

\begin{proof}  Form the $n\times 2n$ matrix $M=(A|I_n)$.  Since $A$ is row equivalent
to $I_n$, there is a sequence of elementary row operations so that $M$ is
row equivalent to $(I_n|B)$.  Eliminating all columns from the right half
of $M$ except the $j^{th}$ column yields the matrix $(A|e_j)$.  The same
sequence of elementary row operations states that the matrix $(A|e_j)$ is
row equivalent to $(I_n|B_j)$ where $B_j$ is the $j^{th}$ column of $B$.  It
follows that $B_j$ is the solution to the system of linear equations
$Ax=e_j$ and that the matrix product
\[
AB = (AB_1|\cdots|AB_n) = (e_1|\cdots|e_n) = I_n.
\]
So $AB=I_n$.

We claim that $BA=I_n$ and hence that $A$ is invertible.  To verify this claim
form the $n\times 2n$ matrix $N=(I_n|A)$.  Using the same sequence of
elementary row operations again shows that $N$ is row equivalent to $(B|I_n)$.
By construction
the matrix $B$ is row equivalent to $I_n$.  Therefore, there is a unique
solution to the system of linear equations $Bx=e_j$.  Now eliminating all
columns except the $j^{th}$ from the right hand side of the matrix $(B|I_n)$
shows that the solution to the system of linear equations $Bx=e_j$ is just
$A_j$, where $A_j$ is the $j^{th}$ column of $A$.  It follows that
\[
BA = (BA_1|\cdots|BA_n) = (e_1|\cdots|e_n) = I_n.
\]
Hence $BA=I_n$.  \end{proof}

\begin{theorem} \label{invertequiv}
Let $A$ be an $n\times n$ matrix.  Then the following are
equivalent:
\begin{itemize}
\item[(a)]  $A$ is invertible. \index{invertible}
\item[(b)] The equation $Ax=b$ has a unique solution for each
$b\in\R^n$.
\item[(c)]  The only solution to $Ax=0$ is $x=0$.
\item[(d)]  $A$ is row equivalent to $I_n$.
\end{itemize}
\end{theorem}

\begin{proof} $(a) \Rightarrow (b)$ This implication
is just Proposition~\ref{P:inv=>unique}.

$(b) \Rightarrow (c)$ This implication is straightforward --- just
take $b=0$ in \eqref{squarematrix}.

$(c) \Rightarrow (d)$  This implication is just a restatement of
Chapter~\ref{lineq}, Corollary~\ref{consistent}.

$(d) \Rightarrow (a)$.  This implication is just
Proposition~\ref{P:row=>inv}. \end{proof}


\subsection*{A Method for Computing Inverse Matrices}

The proof of Proposition~\ref{P:row=>inv} gives a constructive method
for finding the inverse of any invertible square matrix.

\begin{theorem}  \label{T:AIn}\index{inverse!computation}
Let $A$ be an $n\times n$ matrix that is row equivalent to
$I_n$ and let $M$ be the $n\times 2n$ augmented matrix
\begin{equation}  \label{e:M}
M = (A | I_n).
\end{equation}
Then the matrix $M$ is row equivalent to $(I_n | A\inv)$.
\end{theorem}

\subsubsection*{An Example}

Compute the inverse of the matrix
\[
A = \left(\begin{array}{rrr} 1 & 2 & 0 \\ 0 & 1 & 3 \\ 0 & 0 & 1
\end{array}\right).
\]
Begin by forming the $3\times 6$ matrix
\[
M = \left(\begin{array}{rrr|rrr} 1 & 2 & 0 & 1 & 0 & 0 \\
0 & 1 & 3 & 0 & 1 & 0 \\ 0 & 0 & 1 & 0 & 0 & 1
\end{array}\right).
\]
To put $M$ in row echelon form by row reduction, first subtract
3 times the $3^{rd}$ row from the $2^{nd}$ row, obtaining
\[
\left(\begin{array}{rrr|rrr} 1 & 2 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 1 & -3 \\ 0 & 0 & 1 & 0 & 0 & 1
\end{array}\right).
\]
Second, subtract 2 times the $2^{nd}$ row from the $1^{st}$ row, obtaining
\[
\left(\begin{array}{rrr|rrr} 1 & 0 & 0 & 1 & -2 & 6 \\
0 & 1 & 0 & 0 & 1 & -3 \\ 0 & 0 & 1 & 0 & 0 & 1
\end{array}\right).
\]
Theorem~\ref{T:AIn} implies that
\[
A\inv = \left(\begin{array}{rrr} 1 & -2 & 6 \\ 0 & 1 & -3 \\ 0 & 0 & 1
\end{array}\right),
\]
which can be verified by matrix multiplication.

\subsubsection*{Computing the Inverse Using \Matlab}

There are two ways that we can compute inverses using \Matlab.
Either we can perform the row reduction of \eqref{e:M} directly
or we can use the \Matlab the command {\tt inv}.  We illustrate
both of these methods. First type {\tt e3\_7\_4} to recall the matrix
\begin{matlabEquation}\label{MATLAB:31}
A = \left(\begin{array}{rrr} 1 & 2 & 4 \\ 3 & 1 & 1 \\ 2 & 0 & -1
\end{array}\right).
\end{matlabEquation}

To perform the row reduction of \eqref{e:M} we need to form the matrix
$M$. The \Matlab command for generating an $n\times n$ identity
matrix is {\tt eye(n)}.  Therefore, typing
\begin{verbatim}
M = [A eye(3)]
\end{verbatim} \index{\computer!eye}
in \Matlab yields the result
\begin{verbatim}
M =
     1     2     4     1     0     0
     3     1     1     0     1     0
     2     0    -1     0     0     1
\end{verbatim}
Now row reduce $M$ to reduced echelon form as follows.  Type
\begin{verbatim}
M(3,:) = M(3,:) - 2*M(1,:)
M(2,:) = M(2,:) - 3*M(1,:)
\end{verbatim}
obtaining
\begin{verbatim}
M =
     1     2     4     1     0     0
     0    -5   -11    -3     1     0
     0    -4    -9    -2     0     1
\end{verbatim}
Next type
\begin{verbatim}
M(2,:) = M(2,:)/M(2,2)
M(3,:) = M(3,:) + 4*M(2,:)
M(1,:) = M(1,:) - 2*M(2,:)
\end{verbatim}
to obtain
{\scriptsize
\begin{verbatim}
M =
    1.0000         0   -0.4000   -0.2000    0.4000         0
         0    1.0000    2.2000    0.6000   -0.2000         0
         0         0   -0.2000    0.4000   -0.8000    1.0000
\end{verbatim}
  \normalsize}
Finally, type
\begin{verbatim}
M(3,:) = M(3,:)/M(3,3)
M(2,:) = M(2,:) - M(2,3)*M(3,:)
M(1,:) = M(1,:) - M(1,3)*M(3,:)
\end{verbatim}
to obtain
{\scriptsize\begin{verbatim}
M =
    1.0000         0         0   -1.0000    2.0000   -2.0000
         0    1.0000         0    5.0000   -9.0000   11.0000
         0         0    1.0000   -2.0000    4.0000   -5.0000
\end{verbatim}
\normalsize}
Thus $C=A\inv$ is obtained by extracting the last three columns
of $M$ by typing
\begin{verbatim}
C = M(:,[4 5 6])
\end{verbatim}
which yields
\begin{verbatim}
C =
   -1.0000    2.0000   -2.0000
    5.0000   -9.0000   11.0000
   -2.0000    4.0000   -5.0000
\end{verbatim}
You may check that $C$ is the inverse of $A$ by typing {\tt A*C}
and {\tt C*A}.

In fact, this entire scheme for computing the inverse of a
matrix has been preprogrammed into \Matlab.  Just type
\begin{verbatim}
inv(A)
\end{verbatim} \index{\computer!inv}
to obtain
\begin{verbatim}
ans =
   -1.0000    2.0000   -2.0000
    5.0000   -9.0000   11.0000
   -2.0000    4.0000   -5.0000
\end{verbatim}

We illustrate again this simple method for computing the inverse
of a matrix $A$.  For example, reload the matrix in \eqref{eq:5matrix}
by typing \verb+ e3_1_4+ and obtaining:
\begin{verbatim}
A =
     5    -4     3    -6     2
     2    -4    -2    -1     1
     1     2     1    -5     3
    -2    -1    -2     1    -1
     1    -6     1     1     4
\end{verbatim}
The command {\tt B = inv(A)} stores the inverse of the matrix $A$
in the matrix $B$, and we obtain the result
\begin{verbatim}
B =
   -0.0712    0.2856   -0.0862   -0.4813   -0.0915
   -0.1169    0.0585    0.0690   -0.2324   -0.0660
    0.1462   -0.3231   -0.0862    0.0405    0.0825
   -0.1289    0.0645   -0.1034   -0.2819    0.0555
   -0.1619    0.0810    0.1724   -0.1679    0.1394
\end{verbatim}
This computation also illustrates the fact that even when the matrix
$A$ has integer entries, the inverse of $A$ usually has noninteger
entries.

Let $b=(2,-8,18,-6,-1)$.  Then we may use the inverse $B=A\inv$
to compute the solution of $Ax=b$.  Indeed if we type
\begin{verbatim}
b = [2;-8;18;-6;-1];
x = B*b
\end{verbatim}
then we obtain
\begin{verbatim}
x =
   -1.0000
    2.0000
    1.0000
   -1.0000
    3.0000
\end{verbatim}
as desired (see \eqref{eq:5rhs}).  With this computation we have confirmed
the analytical results of the previous subsections.





\EXER

\TEXER

\begin{exercise} \label{c4.8.1}
Verify by matrix multiplication that the following matrices are inverses
of each other:
\[
\left( \begin{array}{rrr}
1  &  0  &  2\\
0  & -1  &  2\\
1  &  0  &  1
\end{array} \right)\AND
\left( \begin{array}{rrr}
-1 &   0 &   2\\
 2 &  -1 &  -2\\
 1 &   0 &  -1
\end{array} \right).
\]

\begin{solution}

If two matrices are inverses of each other, then their product is the
identity matrix.  So:
\[ \matthree{1}{0}{2}{0}{-1}{2}{1}{0}{1}
\matthree{-1}{0}{2}{2}{-1}{-2}{1}{0}{-1} =
\matthree{1}{0}{0}{0}{1}{0}{0}{0}{1}. \]

\end{solution}
\end{exercise}

\begin{exercise} \label{c4.8.2}
Let $\alpha \not=0$ be a real number and let $A$ be an invertible
matrix.  Show that the inverse of the matrix $\alpha A$ is given by
$\frac{1}{\alpha}A^{-1}$.

\begin{solution}

We can compute
\[ (\alpha A)\left(\frac{1}{\alpha}A^{-1}\right) =
\left(\alpha\frac{1}{\alpha}\right)(AA^{-1}) = I. \]
So the inverse of $\alpha A$ is indeed $\frac{1}{\alpha}A^{-1}$.

\end{solution}
\end{exercise}

\begin{exercise} \label{c4.8.3}
Let $A=\mattwo{a}{0}{0}{b}$ be a $2\times 2$ diagonal matrix.
For which values of $a$ and $b$ is $A$ invertible?

\begin{solution}

\ans The matrix $A$ is invertible for $a \neq 0$ and $b \neq 0$.

\soln By Theorem~\ref{invertequiv}, a matrix is invertible if it is row
equivalent to the identity matrix.  If $a = 0$ or if $b = 0$, then
$A$ is not row equivalent to $I_2$ and is therefore not invertible.

\end{solution}
\end{exercise}

\begin{exercise} \label{c4.8.4}
Let $A,B,C$ be general $n\times n$ matrices.  Simplify the expression
$A\inv(BA\inv)\inv(CB\inv)\inv$.

\begin{solution}

\ans The expression simplifies to $C^{-1}$.

\soln Proposition~\ref{P:invprod} states that, if $A$ and $B$ are
invertible matrices such that $AB$ is defined, then $(AB)^{-1} =
B^{-1}A^{-1}$.  Therefore,
\[
A^{-1}(BA^{-1})^{-1}(CB^{-1})^{-1} = A^{-1}AB^{-1}BC^{-1} = C^{-1}.
\]

\end{solution}
\end{exercise}

\noindent In Exercises~\ref{c4.9.3a} -- \ref{c4.9.3b} use row reduction
to find the inverse of the given matrix.
\begin{exercise} \label{c4.9.3a}
$\left(\begin{array}{rrr} 1 & 4 & 5\\ 0 & 1 & -1\\ -2 & 0 & -8
\end{array}\right)$.

\begin{solution}
\ans
$A^{-1} = \dps\frac{1}{10}\matthree{-8}{32}{-9}{2}{2}{1}{2}
{-8}{1}$.

\soln Let
\[
M = (A|I_3) = \left(\begin{array}{rrr|rrr} 1 & 4 & 5 & 1 & 0 & 0 \\
0 & 1 & -1 & 0 & 1 & 0 \\
-2 & 0 & -8 & 0 & 0 & 1 \end{array}\right).
\]
Then, row reduce $M$ to obtain the augmented matrix $(I_3|A^{-1})$.

\end{solution}
\end{exercise}
\begin{exercise} \label{c4.9.3b}
$\left(\begin{array}{rrr} 1 & -1 & -1\\ 0 & 2 & 0\\ 2 & 0 & -1
\end{array}\right)$.

\begin{solution}
\ans
$B^{-1} = \matthree{-1}{-\frac{1}{2}}{1}{0}{\frac{1}{2}}{0}
{-2}{-1}{1}$.

\soln Let
\[
N = (B|I_3) = \left(\begin{array}{rrr|rrr} 1 & -1 & -1 & 1 & 0 & 0 \\
0 & 2 & 0 & 0 & 1 & 0 \\ 2 & 0 & -1 & 0 & 0 & 1 \end{array}\right).
\]
Row reduce $N$ to obtain the augmented matrix $(I_3|B^{-1})$.

\end{solution}
\end{exercise}

\begin{exercise} \label{c4.8.5}
Let $A$ be an $n\times n$ matrix that satisfies
\[
A^3 + a_2A^2 + a_1A + I_n = 0,
\]
where $A^2=AA$ and $A^3=AA^2$.  Show that $A$ is invertible. \\
{\bf Hint:}  Let $B = -(A^2+a_2A+a_1I_n)$ and verify that $AB=BA=I_n$.

\begin{solution}

The matrix $A$ is invertible with inverse $B = -(A^2 + a_2A + a_1)$.
To show this, note that
\[ AB = A(-(A^2 + a_2A + a_1)) = I_n \]
if and only if $A^3 + a_2A^2 + a_1A = -I_n$.  This condition is valid
by definition of $A$, so $A$ is invertible.  Similarly, $BA = I_n$.

\end{solution}
\end{exercise}

\begin{exercise} \label{c4.8.6}
Let $A$ be an $n\times n$ matrix that satisfies
\[
A^m + a_{m-1}A^{m-1} + \cdots + a_1A + I_n = 0.
\]
Show that $A$ is invertible.

\begin{solution}

Given that
\[
A^m + a_{m - 1}A^{m - 1} + \cdots + a_1A + I_n = 0,
\]
we can compute
\[
A(-(A^{m - 1} + a_{m - 1}A^{m - 2} + \cdots + a_1) = I_n.
\]
Therefore, $A$ is an invertible matrix with inverse
\[
-(A^{m - 1} + a_{m - 1}A^{m - 2} + \cdots + a_1).
\]

\end{solution}
\end{exercise}

\begin{exercise} \label{c4.9.6}
For which values of $a,b,c$ is the matrix
\[
A =\left(\begin{array}{rrr} 1 & a & b\\ 0 & 1 & c\\ 0 & 0 & 1
\end{array}\right)
\]
invertible?  Find $A\inv$ when it exists.

\begin{solution}

\ans
The matrix $A$ is invertible for any choice of $a$, $b$, and $c$, and
\[
A^{-1} = \left(\begin{array}{rrc} 1 & -a & -b + ac \\ 0 & 1 & -c 
\\ 0 & 0 & 1 \end{array}\right).
\]

\soln Theorem~\ref{invertequiv} states that a matrix is invertible if
it is row equivalent to $I_n$.  By row reducing the augmented matrix
$(A|I_3)$ as follows:
\[
\left(\begin{array}{rrr|rrr} 1 & a & b & 1 & 0 & 0 \\
0 & 1 & c & 0 & 1 & 0 \\ 0 & 0 & 1 & 0 & 0 & 1
\end{array}\right) \rightarrow \left(\begin{array}{rrr|rrc}
1 & 0 & 0 & 1 & -a & -b + ac \\ 0 & 1 & 0 & 0 & 1 & -c \\
0 & 0 & 1 & 0 & 0 & 1 \end{array}\right)
\]
we show that $A$ is invertible for any choice of $a$, $b$, and
$c$, and find a value for $A^{-1}$.

\end{solution}
\end{exercise}


\CEXER

\noindent In Exercises~\ref{c4.9.7a} -- \ref{c4.9.7b} use row reduction
to find the inverse of the given matrix and confirm your results using the 
command {\tt inv}.
\begin{exercise} \label{c4.9.7a}
\begin{matlabEquation}\label{MATLAB:32}
A=\left(\begin{array}{ccc} 2 & 1 & 3\\ 1 & 2 & 3 \\ 5& 1 & 0
\end{array}\right).
\end{matlabEquation}

\begin{solution}

Type {\tt M = [A eye(3)]} in \Matlabp, then row reduce the augmented 
matrix {\tt M}, obtaining:
\begin{verbatim}
ans =
    1.0000         0         0    0.1667   -0.1667    0.1667
         0    1.0000         0   -0.8333    0.8333    0.1667
         0         0    1.0000    0.5000   -0.1667   -0.1667
\end{verbatim}
Check your answer using {\tt inv(A)} which confirms
\begin{verbatim}
ans =
    0.1667   -0.1667    0.1667
   -0.8333    0.8333    0.1667
    0.5000   -0.1667   -0.1667
\end{verbatim}

\end{solution}
\end{exercise}
\begin{exercise} \label{c4.9.7b}
\begin{matlabEquation}\label{MATLAB:33}
B= \left(\begin{array}{cccr} 0 & 5 & 1 & 3\\ 1 & 5 & 3 & -1\\ 2 & 1 &
0 & -4 \\ 1 & 7 & 2 & 3 \end{array}\right).
\end{matlabEquation}

\begin{solution}

Type {\tt N = [B eye(4)]} in \Matlabp, then row reduce {\tt N} to obtain:
\begin{verbatim}
ans =
1.0000        0        0        0   -1.5714   -0.4286         0    1.4286
     0   1.0000        0        0    0.7429    0.0571    0.2000   -0.4571
     0        0   1.0000        0   -0.9143    0.3143   -0.4000    0.4857
     0        0        0   1.0000   -0.6000   -0.2000   -0.2000    0.6000
\end{verbatim}
The command {\tt inv(B)} returns the right half of this augmented
matrix:
\begin{verbatim}
ans =
   -1.5714   -0.4286         0    1.4286
    0.7429    0.0571    0.2000   -0.4571
   -0.9143    0.3143   -0.4000    0.4857
   -0.6000   -0.2000   -0.2000    0.6000
\end{verbatim}

\end{solution}
\end{exercise}

\begin{exercise} \label{c4.9.8}
Try to compute the inverse of the matrix
\begin{matlabEquation}\label{MATLAB:34}
C = \left(\begin{array}{rrr} 1 & 0 & 3\\ -1 & 2 & -2 \\ 0& 2 & 1
\end{array}\right)
\end{matlabEquation}
in \Matlab using the command {\tt inv}.  What happens --- can you
explain the outcome?

Now compute the inverse of the matrix
\[
\left(\begin{array}{rrr} 1 & \epsilon & 3\\ -1 & 2 & -2 \\ 0& 2 & 1
\end{array}\right)
\]
for some nonzero numbers $\epsilon$ of your choice.  What can be observed
in the inverse if $\epsilon$ is very small?  What happens when $\epsilon$
tends to zero?

\begin{solution}

Typing {\tt inv(C)} in \Matlab yields the response
\begin{verbatim}
Warning: Matrix is singular to working precision.
ans =
   Inf   Inf   Inf
   Inf   Inf   Inf
   Inf   Inf   Inf
\end{verbatim}
Matrix $C$ cannot be inverted because it is not row equivalent to $I_3$.
We can type {\tt rref(C)} to confirm that
\begin{verbatim}
ans =
    1.0000         0    3.0000
         0    1.0000    0.5000
         0         0         0
\end{verbatim}
\para When {\tt C(1,2)} is nonzero, $C$ is invertible.  As $\epsilon
\rightarrow 0$ the entries of $C^{-1}$ approach infinity.  For example,
if $\epsilon = 0.01$, then {\tt inv(C)} yields
\begin{verbatim}
ans =
  600.0000  599.0000 -602.0000
  100.0000  100.0000 -100.0000
 -200.0000 -200.0000  201.0000
\end{verbatim}
At $\epsilon = 0$, $C^{-1}$ does not exist.



\end{solution}
\end{exercise}

\AEXER

\begin{exercise} \label{A3.7.1}
Let $A$ and $B$ be $3\times 3$ invertible matrices so that
\[
A^{-1} = \Matrix{1 & 0 & -1 \\ -1 & -1 &0 \\ 0 & 1 & -1}
\quad\text{and}\quad
B^{-1} = \Matrix{1 & 1 & 1 \\ 1 &1 &0 \\ 1 & 0 & 0}
\]
Without computing $A$ or $B$, determine the following:
\begin{enumeratea}
\item $\rank(A)$
\item The solution to 
\[
Bx=\Matrix{1 \\ 1 \\ 1}
\]
\item $(2BA)^{-1}$
\item The matrix $C$ so that $ACB+3I_3=0.$
\end{enumeratea} 



\begin{solution}
\begin{enumeratea}
\item $A$ is an invertible $3\times 3$ matrix, so $\rank(A)=3$.
\item The solution is 
\[
x = B^{-1}\Matrix{1 \\ 1 \\ 1}= \Matrix{1 & 1 & 1 \\ 1 &1 &0 \\ 1 & 0 & 0} \Matrix{1 \\ 1 \\ 1}=\Matrix{3 \\ 2 \\ 1}
\]
\item 
\[
(2BA)^{-1}=\frac{1}{2}A^{-1}B^{-1}=\frac{1}{2}
\Matrix{1 & 0 & -1 \\  -1 &-1 &0 \\  0 & 1 & -1}
\Matrix{1 & 1 & 1 \\  1 &1 &0 \\  1 & 0 & 0}
=\frac{1}{2}\Matrix{ 0 & 1 & 1 \\ -2 &-2 &-1 \\ 0 & 1 & 0}
\]
\item Recall that multiplication on the left by a matrix is not the same as multiplication on the right. We have that
\begin{align*}
ACB=-3I_3\implies&\;\;  A^{-1}ACB=-3A^{-1}I_3 &&\text{multiplying on the left by $A^{-1}$}\\
\implies & \;\; CB=-3A^{-1}\\
\implies & CBB^{-1}=-3A^{-1}B^{-1}&&\text{multiplying on the right by $B^{-1}$}\\
\implies & C=-3A^{-1}B^{-1}\\
\implies & C=3\Matrix{ 0 & 1 & 1 \\ -2 &-2 &-1 \\ 0 & 1 & 0}
\end{align*}
\end{enumeratea}
\end{solution}
\end{exercise}


\begin{exercise} \label{A3.7.2}
True or False: Determine whether the following statements are true or false, and explain your answer.
\begin{enumeratea}
\item The only $3\times 2$ matrix $A$ so that $Ax = 0 $ for all $x \in \R^2$ is $A=0$.

\item A system of 5 equations in 3 unknowns with the solution $x_1=0, x_2=-3,x_3=1$ must have infinitely many solutions.

\item If $A$ is a $2\times 2$ matrix and $A^2=0$, then $A=0$.

\item  If $u,v\in \R^3$ are perpendicular, then $\left\| u + v \right\| =\left\| u \right\|+\left\| v \right\|$.  

\end{enumeratea}

\begin{solution}
\begin{enumeratea}
\item True:
\[
A=\Matrix{ A e_1 & A e_2}=\Matrix{0 & 0}=\Matrix{ 0 & 0 \\ 0 & 0 \\ 0 & 0}=0
\]
\item False, it may have a unique solution. For example, the system of equations
\[
\Matrix{ 1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 1 & 1 \\ 1 & 0 & 1} = \Matrix{ 0 \\ -3 \\ 1 \\ -2 \\ 1}
\]
has $x_1=0, x_2=-3,x_3=1$ as a unique solution.
\item False: if 
\[
A=\Matrix{0 & 1 \\ 0 & 0}
\]
then $A^2=0$.
\item False:
\[
\Matrix{ 1 \\ 0 \\ 0} + \Matrix{ 0 \\ 1 \\ 0} = \sqrt{2}\neq 2 = \Matrix{ 1 \\ 0 \\ 0} + \Matrix{0 \\ 1 \\ 0}
\]
However, by the Pythagorean theorem, 
\[
\left\|u + v \right\|^2=\left\| u \right\|^2+\left\| v \right\|^2 
\]
\end{enumeratea}
\end{solution}

\end{exercise}





\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../linearAlgebra"
%%% End:

\chapter{Vector Spaces}

\subsection*{Section~\protect{\ref{S:5.1}} Vector Spaces and Subspaces}
\rhead{S:5.1}{VECTOR SPACES AND SUBSPACES}

\exer{c5.1.1}
The set $V_1 \subset \R^3$ is a subspace.
The set $V_1$ contains all vectors $(a,-a,-2a)$,
where $a \in \R$.  We can show that it is closed under
vector addition, since
\[
a(1,-1,-2) + b(1,-1,-2) = (a + b)(1,-1,-2) \in V_1
\]
where $a$ and $b$ are scalars.  The set $V_1$ is closed under scalar
multiplication since
\[
b(a(1,-1,-2) = (ba)(1,-1,-2) \in V_1.
\]

\exer{c5.1.3}
The set $V_3$ is a subspace of $R^3$ since the solution set to
any equation $Ax = 0$ is a space.  This is demonstrated by the
principle of superposition introduced in Section~\ref{S:Superposition}.  
Also, $V_3 = V_1$.

\para   We can show that $V_3 = V_1$ by row reducing to find the
solutions to $Ax = 0$:
\[
\left(\begin{array}{rrr} 1 & 1 & 0 \\ 1 & -1 & 1
\end{array}\right) \longrightarrow \left(\begin{array}{rrr} 1 & 0 &
\frac{1}{2} \\ 0 & 1 & -\frac{1}{2} \end{array}\right).
\]
So all vectors in $V_3$ are of the form $x = s(-\frac{1}{2},
\frac{1}{2}, 1)$, where $s \in \R$.  The vector $x$ is an element
of $V_1$ for each $s$.

\exer{c5.1.4b} \ans $W$ is not a subspace of $V$.

\soln The subset $W$ is closed neither under addition nor under scalar
multiplication.  For example, let $w_1 = (1,4,2)$ and $w_2 = (1,-1,3)$
be elements of $W$.  Then,
\[
w_1 + w_2 = (1,4,2) + (1,-1,3) = (2,3,5)
\]
which is not an element of $W$.

\newpage
\exer{c5.1.4c} $W$ is a subspace of $V$, since $W$ is closed under
addition and scalar multiplication.

\exer{c5.1.4e} $W$ is a subspace of $V$, since $W$ is closed under
addition and scalar multiplication.

\exer{c5.1.5a} \ans The set $S$ is not a subspace.

\soln The set $S$ is closed under addition but not under scalar
multiplication.  To demonstrate, let $x = (1,4,2)$ be an element of $S$. 
Then
\[
-2x = -2(1,4,2) = (-2,-8,-4)
\]
which is not an element of $S$.

\exer{c5.1.5c} The set $S$ is a subspace, since it is closed under
addition and scalar multiplication.

\exer{c5.1.5e} \ans The set $S$ is not a subspace.

\soln The set $S$ is closed under neither addition nor scalar
multiplication.  For example, let $x_1$ and $x_2$ be solutions to the
equation $Ax = b$.  Then,
\[
A(x_1 + x_2) = Ax_1 + Ax_2 = b + b = 2b,
\]
so $(x_1 + x_2)$ is not an element of $S$.

\exer{c5.1.7a}
\ans Let $V$ be the subset of solutions $(x,y)$ to $ax + by = c$.
The subset $V$ is a subspace when $c = 0$ and is not a subspace
when $c \neq 0$. 

\soln Let $(x_1,y_1)$ and $(x_2,y_2)$ be elements of $V$.  Then
\[
a(x_1 + x_2) + b(y_1 + y_2) = (ax_1 + by_1) + (ax_2 + by_2) =
c + c = 2c.
\]
Thus $V$ is closed under addition only when $2c = c$, so $c = 0$.
Similarly, for any scalar $r$,
\[
r(ax_1 + by_1) = cr.
\]
So $V$ is closed under scalar multiplication only when $rc = c$ for
any scalar $r$.  Thus, $c = 0$.

\exer{c5.1.8}
The set of all solutions to the differential equation $\dot{x} = 2x$ is
indeed a subspace of $\CCone$.  To demonstrate, let $x_1$ and $x_2$
be elements of this set.  The set is closed under addition since
\[
\frac{d}{dt}(x_1 + x_2) = \frac{d}{dt}(x_1) + \frac{d}{dt}(x_2)
= 2x_1 + 2x_2 = 2(x_1 + x_2)
\]
and closed under scalar multiplication since, for any real scalar $r$,
\[
\frac{d}{dt}(rx_1) = r\frac{d}{dt}(x_1) = 2(rx_1).
\]
Note that this problem provides another example of the principle of
superposition.



\newpage
\subsection*{Section~\protect{\ref{S:5.2}} Construction of Subspaces}
\rhead{S:5.2}{CONSTRUCTION OF SUBSPACES}

\exer{c5.2.1a} \ans The subspace of solutions can be spanned by the vectors 
$(1,0,-4)^t$ and $(0,1,2)^t$.

\soln All solutions to $4x - 2y + z = 0$ can be written in the form
\[
\vecthree{x}{y}{z} = \cvecthree{x}{y}{2y - 4x}
= x\vecthree{1}{0}{-4} + y\vecthree{0}{1}{2}.
\]

\exer{c5.2.1c}  \ans The subspace of solutions can be spanned by the vectors 
$(1,0,-1)^t$ and $(0,1,-1)^t$.

\soln All solutions to $x + y + z = 0$ can be written in the form
\[
\vecthree{x}{y}{z} = \cvecthree{x}{y}{-x-y}
= x\vecthree{1}{0}{-1} + z\vecthree{0}{1}{-1}.
\]

\exer{c5.2.2a}
\ans The subspace of solutions is spanned by the vectors
\[
(-2,1,0,0,0)^t \AND (-1,0,-4,1,0)^t.
\]

\soln Let $x = (x_1,\dots ,x_5)$ be a solution to $Ax = 0$.  All
solutions to this equation have the form
\[
\left(\begin{array}{r} x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{array}\right) = \left(\begin{array}{c} -2x_2 - x_4 \\ x_2 \\
-4x_4 \\ x_4 \\ 0 \end{array}\right) = x_2\left(\begin{array}{r}
-2 \\ 1 \\ 0 \\ 0 \\ 0 \end{array}\right) +
x_4\left(\begin{array}{r} -1 \\ 0 \\ -4 \\ 1 \\ 0
\end{array}\right).
\]

\exer{c5.2.2c}
\ans The subspace of solutions to $Ax = 0$ is spanned by the vector
$(-2,-1,1)^t$.

\soln Let $x = (x_1,x_2,x_3)$ be a solution to $Ax = 0$.  All solutions
to this equation have the form
\[
\vecthree{x_1}{x_2}{x_3} = \vecthree{-2x_3}{-x_3}{x_3} =
x_3\vecthree{-2}{-1}{1}.
\]

\exer{c5.2.3}
\ans The matrix $A$ whose subspace of solutions in $\R^4$ is the span of
$v_1$ and $v_2$ is
\[
A = \left(\begin{array}{rrrr} 1 & 1 & 0 & 0 \\ 0 & 0 & 1 & 1
\end{array}\right).
\]

\soln Note that all vectors $x$ in the spanning set of $v_1$ and $v_2$
are of the form:
\[
x = \left(\begin{array}{r} x_1 \\ x_2 \\ x_3 \\ x_4
\end{array}\right)
= a\left(\begin{array}{r} 1 \\ -1 \\ 0 \\ 0 \end{array}\right) + 
b\left(\begin{array}{r} 0 \\ 0 \\ 1 \\ -1 \end{array}\right) =
\left(\begin{array}{r} a \\ -a \\ b \\ -b \end{array}\right).
\]
Therefore, $x_1 = -x_2$ and $x_3 = -x_4$.  So,
\[
\begin{array}{rrrrrrrrl}
x_1 & + & x_2 & & & & & = & 0 \\
& & & & x_3 & + & x_4 & = & 0. \end{array}
\]
The matrix of this system is $A$.

\exer{c5.2.5}
\ans The vector $(2,20,0)^t$ is in the span of $w_1$ and $w_2$. 
Specifically, $v = -4w_1 + 6w_2$.

\soln Note that, for some real numbers $a$ and $b$,
\[
(2,20,0)^t = aw_1 + bw_2 = a(1,1,3)^t + b(1,4,2)^t
\]
if $v$ is in the span of $w_1$ and $w_2$.
This corresponds to the linear system
\[
\begin{array}{rrrrr}
a & + & b & = 2 \\
a & + & 4b & = 20 \\
3a & + & 2b & = 0 \end{array}
\]
To find $a$ and $b$, row reduce the augmented matrix of the system:
\[
\left(\begin{array}{rr|r} 1 & 1 & 2 \\ 1 & 4 & 20 \\
3 & 2 & 0 \end{array}\right) \longrightarrow
\left(\begin{array}{rr|r} 1 & 0 & -4 \\ 0 & 1 & 6 \\
0 & 0 & 0 \end{array}\right).
\]
The system is consistent; $a = -4$ and $b = 6$.

\exer{c5.2.6b} The function $y(t) = t^4$ is not in $W$.

\exer{c5.2.6d}
\ans The function $y(t) = 0.5t^2$ is an element of $W$, but the set
$\{y(t),x_2(t)\}$ does not span $W$.

\soln When $a = 0$ and $b = 0.5$,
\[ 
ax_1(t) + bx_2(t) = 0.5x_2(t) = 0.5t^2 = y(t). 
\]
In this case, there exist functions in $W$ that are not in 
$\Span\{y(t),x_2(t)\}$.  For example, the function $x_1(t) = 1$ cannot
be written as a linear combination of $x_2(t)$ and $y(t)$.

\exer{c5.2.8a}
Every vector $x \in \Span\{v\}$ is of the form $x = av
= av + 0v$, so $x \in \Span\{v,v\}$.  Therefore, $\Span\{v\}
\subset \Span\{v,v\}$.  Every vector $y \in \Span\{v,v\}$ is of the
form 
\[
y = bv + cv = (b + c)v \in \Span\{v\}.
\]
Therefore $\Span\{v,v\} \subset \Span\{v,v\}$, so the two spans are equal.

\exer{c5.2.9}
Since $W = \Span\{w_1,\dots ,w_k\}$, every vector $x \in W$ can be
written as the linear combination
\[ x = a_1w_1 + \cdots + a_kw_k \]
for some choice of $a_1 \dots a_k$.  Since $w_{k + 1}$ is a vector in
$W$, it can therefore be written as
\[ w_{k + 1} = b_1w_1 + \cdots + b_kw_k \]
and any vector $x \in W$ can be written as
\[ \begin{array}{rcl}
x & = &
a_1w_1 + \cdots + a_kw_k + a_{k+1}w_{k+1} \\
& = & a_1w_1 + \cdots + a_kw_k + a_{k+1}b_1w_1 + \cdots + a_{k+1}b_kw_k
\\ & = & (a_1 + a_{k+1}b_1)w_1 + \cdots + (a_k + a_{k+1}b_k)w_k.
\end{array} \]
So, $W = \Span\{w_1,\dots ,w_{k+1}\}$.



\subsection*{Section~\protect{\ref{S:5.3}} Spanning Sets and \Matlab}
\rhead{S:5.3}{SPANNING SETS AND MATLAB}

\exer{c5.3.1a}
Type {\tt null(A)} in \Matlab to find that the set of solutions to
$Ax = 0$ is spanned by the vectors
\[
\left(\begin{array}{r} 0.3225 \\ 0.8931 \\ -0.0992 \\ 0.2977
\end{array}\right) \AND \left(\begin{array}{r} 0 \\ -0.1961 \\
0.5883 \\ 0.7845 \end{array}\right).
\]

\exer{c5.3.1c} The set of solutions to $Ax = 0$ is spanned by the vector
\[
\vecthree{-0.8452}{-0.1690}{0.5071}.
\]

\exer{c5.3.3}
\ans The solution set of $Bx = 0$ is
\[
\left(\begin{array}{r} x_1 \\ x_2 \\ x_3 \\ x_4 \end{array}\right)
= \left(\begin{array}{c} -x_3 + \frac{3}{4}x_4 \\ -3x_3 + 2x_4 \\
x_3 \\ x_4 \end{array}\right) = x_3\left(\begin{array}{r} -1 \\ -3 \\
1 \\ 0 \end{array}\right) + x_4\left(\begin{array}{r} \frac{3}{4} \\
2 \\ 0 \\ 1 \end{array}\right).
\]

\soln Row reduce $B$:
\[
\left(\begin{array}{rrrr} -4 & 0 & 4 & 3 \\ -4 & 1 & -1 & 1
\end{array}\right) \longrightarrow \left(\begin{array}{rrrr}
1 & 0 & 1 & -\frac{3}{4} \\ 0 & 1 & 3 & -2 \end{array}\right).
\]

The solution obtained by row reduction is not the same as the one
obtained using {\tt null}, but the solution vectors are linear
combinations of the \Matlab solution vectors, so the answers are
equivalent.  By row reducing the matrix {\tt [null(B) x]}, where
$x = (-1,-3,1,0)$, we find that
\[
\left(\begin{array}{r} -1 \\ -3 \\ 1 \\ 0 \end{array}\right) =
-3.1009\left(\begin{array}{r} 0.3225 \\ 0.8931 \\ -0.0992 \\ 0.2977
\end{array}\right) + 1.1767\left(\begin{array}{r} 0 \\ -0.1961 \\
0.5883 \\ 0.7845 \end{array}\right).
\]
By row reducing the matrix {\tt [null(B) y]} where $y = (\frac{3}{4},
2,0,1)$ we find that:
\[
\left(\begin{array}{r} \frac{3}{4} \\ 2 \\ 0 \\ 1 \end{array}\right) =
2.3257\left(\begin{array}{r} 0.3225 \\ 0.8931 \\ -0.0992 \\ 0.2977
\end{array}\right) + 0.3922\left(\begin{array}{r} 0 \\ -0.1961 \\
0.5883 \\ 0.7845 \end{array}\right).
\]

\exer{c5.3.4b} \ans Vector $v_2$ is not an element of $W$.

\soln Create the augmented matrix {\tt aug2 = [A v2']}.  Row reducing
{\tt aug2} yields
\begin{verbatim}
ans =
     1     0     0     0
     0     1     0     0
     0     0     1     0
     0     0     0     1
     0     0     0     0
\end{verbatim}
There is a pivot point in the last column, so the linear system
$aw_1 + bw_2 + cw_3 = v_2$ is inconsistent.



\subsection*{Section~\protect{\ref{S:5.4}} Linear Dependence and Linear
Independence}
\rhead{S:5.4}{LINEAR DEPENDENCE AND LINEAR INDEPENDENCE}

\exer{c5.4.1}
To show that the set of vectors $\{w_1,w_2\}$ is linearly dependent,
show that there exist nonzero $a$ and $b$ such that
$aw_1 + bw_2 = 0$.  For the set $\{w,0\}$, if $a = 0$ and $b = 1$,
then $0w + 1(0) = 0$, so the set is linearly dependent.  For the
set $\{w,-w\}$, if $a = 1$ and $b = 1$, then
$w - w = 0$, so the set is linearly dependent.

\exer{c5.4.3}
\ans The set is linearly dependent.

\soln Let $A$ be the matrix whose columns are $u_1$, $u_2$, and $u_3$. 
The set $\{u_1,u_2,u_3\}$ is linearly dependent if there exists
a nonzero vector $r = (r_1,r_2,r_3)$ such that $r_1u_1 + r_2u_2 +
r_3u_3 = 0$, that is, if the homogeneous system $Ar = 0$ has a
nonzero solution.  Row reduce:
\[
\matthree{1}{2}{10}{-1}{1}{2}{1}{-2}{-6} \longrightarrow
\matthree{1}{0}{2}{0}{1}{4}{0}{0}{0}.
\]
So, $Ar = 0$ when $r = r_3(-2,-4,1)$.
The value of $r$ is nonzero for $r_3 \neq 0$, so the set is indeed
linearly dependent.
As an example, let $r_3 = 1$.  Then,
\[
-4u_1 - 2u_2 + u_3 = -2(1,-1,1) - 4(2,1,-2) + (10,2,-6) =
(0,0,0) = 0.
\]

\exer{c5.4.5}
\ans The polynomials $p_1(t) = 2 + t$, $p_2(t) = 1 + t^2$, and $p_3(t) =
t - t^2$ are linearly independent in $\CCone$.  

\soln We can determine this
by noting that the polynomials are linearly dependent if there exists
a nonzero vector $r = (r_1,r_2,r_3)$ such that $r_1p_1 + r_2p_2 +
r_3p_3 = 0$.  It is convenient to represent each polynomial as a
vector $(a,b,c) = p(t) = a + bt + ct^2$.  Thus, $p_1(t) = (2,1,0)$, 
$p_2(t) = (1,0,1)$, and $p_3(t) = (0,1,-1)$.  Solve the homogeneous
system $Ar = 0$, where $A$ is the matrix whose columns are $p_1$,
$p_2$, and $p_3$, by row reduction.
\[ \matthree{2}{1}{0}{1}{0}{1}{0}{1}{-1} \longrightarrow
\matthree{1}{0}{0}{0}{1}{0}{0}{0}{1}. \]
Therefore, there are no nonzero values of $r$ for which $r_1p_1 + 
r_2p_2 + r_3p_3 = 0$, and the polynomials are linearly independent.

\exer{c5.4.7}
To show that the vectors $u_1 + u_2$, $u_2 + u_3$ and $u_3 + u_1$
are linearly independent, we assume that there exist scalars $r_1$,
$r_2$, $r_3$ such that
\[ r_1(u_1 + u_2) + r_2(u_2 + u_3) + r_3(u_3 + u_1) = 0. \]
We then prove that $r_1 = r_2 = r_3 = 0$, as follows.
Use distribution to obtain
\[ (r_1 + r_3)u_1 + (r_1 + r_2)u_2 + (r_2 + r_3)u_3 = 0. \]
Since the set $\{u_1,u_2,u_3\}$ is linearly independent,
\[ \begin{array}{rrrrrcl}
r_1 & & & + & r_3 & = & 0 \\
r_1 & + & r_2 & & & = & 0 \\
& & r_2 & + & r_3 & = & 0. \end{array} \]
Solving this system yields $r_1 = r_2 = r_3 = 0$,
so the set $\{u_1 + u_2,u_2 + u_3,u_3 + u_1\}$ is linearly
independent.

\exer{c5.4.8b} \ans The set $\{w_1,w_2,w_3,w_4\}$ is linearly dependent.

\soln Create the matrix {\tt A} associated to the set
$\{w_1,w_2,w_3,w_4\}$, and row reduce to solve for
$r = (r_1,r_2,r_3,r_4)$, obtaining
\begin{verbatim}
ans =
    1.0000         0         0    0.1429
         0    1.0000         0    0.2857
         0         0    1.0000    0.7143
\end{verbatim}
Therefore, $-0.1429w_1 - 0.2857w_2 - 0.7143w_3 + w_4 = 0$.

\exer{c5.4.9}
(a) The set of commands to perform this experiment is:
\begin{verbatim}
y1 = rand(3,1);
y2 = rand(3,1);
y3 = rand(3,1);
A = [y1 y2 y3];
rref(A)
\end{verbatim}
If the resulting matrix is $I_3$, then the set is linearly
independent.

(b) The most likely outcome is that all five trials result in
linearly independent sets.

(c) Every trial yields a linearly dependent set of vectors.



\subsection*{Section~\protect{\ref{S:5.5}} Dimension and Bases}
\rhead{S:5.5}{DIMENSION AND BASES}

\exer{c5.5.1}  
By Theorem~\ref{basis=span+indep},
${\cal U}$ is a basis for $\R^3$ if the vectors of ${\cal U}$ are
linearly independent and span $\R^3$.  By Lemma~\ref{L:computerank},
the dimension of ${\cal U}$ is equal to the rank of the matrix whose
rows are $u_1$, $u_2$, and $u_3$.  Row reduce this matrix:
\[
\matthree{1}{1}{0}{0}{1}{0}{-1}{0}{1} \longrightarrow
\matthree{1}{0}{0}{0}{1}{0}{0}{0}{1}.
\]
So $\dim({\cal U}) = 3 = \dim(\R^3)$, and we need now only show that
$u_1$, $u_2$, and $u_3$ are linearly independent, which we can do by
row reducing the matrix whose columns are the vectors of ${\cal U}$ as
follows:
\[
\matthree{1}{0}{-1}{1}{1}{0}{0}{0}{1} \longrightarrow
\matthree{1}{0}{0}{0}{1}{0}{0}{0}{1}.
\]
Therefore, there is no nonzero solution to the equation
${\cal U}r = 0$, so the vectors of ${\cal U}$ are linearly independent
and ${\cal U}$ is a basis for $\R^3$.

\exer{c5.5.3}
\ans The vectors $(1,1,1,0)$ and $(-2,-2,0,1)$ form a basis for the
nullspace of $A$; therefore the dimension of the nullspace is $2$.

\soln Find the set of solutions to $Ax = 0$ by solving
\[
\left(\begin{array}{rrrr} 1 & 0 & -1 & 2 \\ 1 & -1 & 0 & 0 \\ 4
& -5 & 1 & -2 \end{array}\right) \left(\begin{array}{r} x_1 \\ x_2
\\ x_3 \\ x_4 \end{array}\right) = 0.
\]
To solve, row reduce $A$, obtaining
\[
\left(\begin{array}{rrrr} 1 & 0 & -1 & 2 \\ 0 & 1 & -1 & 2 \\ 0
& 0 & 0 & 0 \end{array}\right).
\]
So the set of solutions to $Ax = 0$ can be written
\[
\left(\begin{array}{r} x_1 \\ x_2 \\ x_3 \\ x_4
\end{array}\right) = \left(\begin{array}{c} x_3 - 2x_4 \\ x_3 - 2x_4
\\ x_3 \\ x_4 \end{array}\right) = x_3\left(\begin{array}{r} 1 \\ 1
\\ 1 \\ 0 \end{array}\right) + x_4\left(\begin{array}{r} -2 \\ -2
\\ 0 \\ 1 \end{array}\right).
\]

\exer{c5.5.5}
The set $P_n$ is a subspace if it is closed under addition and
scalar multiplication.  Let $x(t) = a_0 + a_1t + \cdots +
a_nt^n$, $y(t) = b_0 + b_1t + \cdots + b_nt^n$ and $s \in \R$.
Then
\[
\begin{array}{l}
x(t) + y(t) = (a_0 + b_0) + (a_1 + b_1)t + \cdots + (a_n + b_n)t^n \in P_n.
\\
cx(t) = c(a_0 + a_1t + \cdots + a_nt^n) = ca_0 + ca_1t + \cdots + ca_nt^n
\in P_n.
\end{array}
\]
The dimension of $P_2$ is 3, since $x_1 = 1$, $x_2 = t$, and
$x_3 = t^2$ form a basis for $P_2$.  The dimension of $P_n$ is
$n + 1$.

\exer{c5.5.7}
(a) The matrix $A$ is symmetric because, by \Ref{e:transposeprod},
\[
A^t = (u^tu)^t = u^tu = A.
\]
To show that $\rank(A) = 1$, let $v$ be a vector such that $u \cdot
v = 0$.  This implies $uv^t = 0$, and thus $Av^t = u^t(uv^t) = 0$
for all vectors $v$.  The span of vectors perpendicular to $u$ has
dimension $n - 1$, so $\null(A) \geq n - 1$.  We know that $uu^t
= u \cdot u = ||u||$.  Thus, $Au^t = u^tuu^t = ||u||u^t$.  Since
$u$ is a nonzero vector, $||u|| \neq 0$, so $Au^t$ is a nonzero
multiple of $u^t$.  Therefore, $A$ is not the zero matrix, so
$\null(A) = n - 1$, and therefore $\rank(A) = 1$.

(b) The matrix $P$ is invertible if $P$ is row equivalent to $I_n$,
that is, if $\rank(P) = n$.  To show that this is true, again let $v$
be any vector perpendicular to $u$.  Then:
\[
Pv^t = (I_n + u^tu)v^t = v^t + 0 = v^t.
\]
Thus, $\rank(P) \geq n - 1$.  In addition
\[
Pu^t = (I_n + u^tu)u^t = u^t + ||u||u^t = (1 + ||u||)u^t
\]
which, since $||u|| > 0$, is a nonzero multiple of $u^t$.  Therefore,
$\rank(P) = n$ and $P$ is invertible.



\newpage
\subsection*{Section~\protect{\ref{S:5.6}} The Proof of the Main Theorem}
\rhead{S:5.6}{THE PROOF OF THE MAIN THEOREM}

\exer{c5.7.1a}
\ans The span of $v_1$ and $v_2$ is a plane with normal vector
$N = n_3(-\frac{3}{2}, 1, 1)$, where $n_3$ is a nonzero scalar.

\soln If $v_1$ and $v_2$ are linearly independent, then they span a plane
in $\R^3$.  If they are linearly dependent, that is, if $v_1 =
\alpha v_2$ for some scalar $\alpha$, then they span a line in $\R^3$.
In this case, there is no scalar $\alpha$ such that $(2,1,2) =
\alpha(0,-1,1)$, so the span of $v_1$ and $v_2$ has dimension two.
The vector $N = (n_1,n_2,n_3)$ is found by observing that:
\[
\begin{array}{rrrrrcl}
2n_1 & + & n_2 & + & 2n_3 & = & 0 \\
& & -n_2 & + & n_3 & = & 0 \end{array}
\]
which is a linear system in two equations.  Solve for $N$ by row
reducing the corresponding matrix:
\[
\left(\begin{array}{rrr} 2 & 1 & 2 \\ 0 & -1 & 1 \end{array}\right)
\longrightarrow \left(\begin{array}{rrr} 1 & 0 & \frac{3}{2} \\ 0 &
1 & -1 \end{array}\right).
\]

\exer{c5.7.1c} \ans The span of $v_1$ and $v_2$ is a plane with normal
vector $N = n_3(0,0,1)$, where $n_3$ is a nonzero scalar.

\soln There is no scalar $\alpha$ such that $(0,1,0) = \alpha(4,1,0)$. 
Let $N = (n_1,n_2,n_3)$ be the vector perpendicular to the plane.  Then:
\[
\begin{array}{rrrrrcl}
& & n_2 & & & = & 0 \\
4n_1 & + & n_2 & & & = & 0 \end{array}
\]
Solve for $N$ by substitution to find that $n_1 = n_2 = 0$, and
$n_3$ can be any nonzero real scalar.

\exer{c5.6.1}
(a) The largest value that $r$ can have is $5$, since the matrix has
$5$ columns.  Thus, the reduced echelon form matrix can have at most
$5$ pivot points.

(b) The equation $Ax = b$ has a solution if the rank of the augmented
matrix $(A|b)$ is $r$.  If $\rank (A|b)$ is greater than $r$, then
there is a pivot in the $6^{th}$ column and the system is
inconsistent, so there is no solution.

(c) The null space has dimension $5 - r$.

(d) The number of parameters needed to describe the solution to
$Ax = b$ is $5 - r$, since $5 - r$ parameters are needed to describe
the solutions to $Ax = 0$, and the solutions to the inhomogeneous
system are obtained by adding the solutions of the homogeneous system
to one solution of the inhomogeneous system.

\exer{c5.6.3}
There is no scalar $\alpha$ such that $(2,3,1) = \alpha(1,1,3)$, so
$v_1$ and $v_2$ are linearly independent.
The set of linear combinations of $v_1$ and $v_2$ is the set of
solutions to
\[
\begin{array}{rrrrrrl}
2a_1 & + & 3a_1 & + & a_3 & = & 0 \\
a_1 & + & a_2 & + & 3a_3 & = & 0. \end{array}
\]
Row reducing this system yields $a_1 = -8a_3$ and $a_2 = 5a_3$.
Let $a_3 = 0$.  Then every linear combination of $v_1$ and $v_2$ is
of the form
\[
8x_1 - 5x_2 - x_3 = 0
\]
which is the equation of a plane in $\R^3$.  The normal vector to this
plane is $N = (8,-5,-1)$.  Row reduce the matrix whose columns
are the vectors $v_1$, $v_2$, and $N$ to verify that these vectors
are linearly independent.
\[
\matthree{2}{1}{8}{3}{1}{-5}{1}{3}{-1} \longrightarrow
\matthree{1}{0}{0}{0}{1}{0}{0}{0}{1}.
\]
So the vectors are indeed linearly independent, verifying
Lemma~\ref{extendindep}.

\exer{c5.6.4}
(a) \ans The span has dimension $3$ for $\lambda \neq 2$, and 
the set $\{w_1,w_2,w_3\}$ is a basis for $\R^3$.

\soln Find the dimension of the span by creating a matrix with rows
$w_1$, $w_2$, $w_3$, and $w_4$, then row reducing:
\begin{equation} \label{exeq:5.6.4}
\left(\begin{array}{rrr} 2 & -2 & 1 \\ -1 & 2 & 0 \\ 3 & -2 &
\lambda \\ -5 & 6 & -2 \end{array}\right) \longrightarrow
\left(\begin{array}{rrc} 1 & -1 & \frac{1}{2} \\ 0 & 1 & \frac{1}{2}
\\ 0 & 0 & \lambda - 2 \\ 0 & 0 & 0 \end{array}\right).
\end{equation}
If $\lambda = 2$, then the dimension of the span will
be $2$ and if $\lambda \neq 2$, then the dimension of the span
will be $3$.  For example, let $\lambda = -1$.

\para Verify by row reduction that the set $\{w_1,w_2,w_3\}$ is a basis
for $\R^3$ and that the set $\{w_1,w_2,w_4\}$ is not a basis for $R^3$. 

(b) If $\lambda = 2$, then the dimension of span$\{w_1,w_2,w_3,w_4\}$
is $2$, as shown by equation~\Ref{exeq:5.6.4}.

\exer{c5.6.6}
\ans The vectors $(1,0,0,-\frac{1}{2},\frac{3}{2})$, $(0,1,0,\frac{1}{2},
-\frac{1}{2})$, and $(0,0,1,\frac{1}{2},\frac{3}{2})$ form a basis
for the subspace spanned by $u_1, \dots ,u_5$.

\soln Row reduce the matrix {\tt M}, whose
rows are $u_1$, $u_2$, $u_3$, $u_4$ and $u_5$.  According to 
Lemma~\ref{extendindep}, the rows of the
reduced echelon matrix form a basis for $\{u_1,\dots ,u_5\}$.  The
command {\tt rref(M)} yields:
\begin{verbatim}
ans =
    1.0000         0         0   -0.5000    1.5000
         0    1.0000         0    0.5000   -0.5000
         0         0    1.0000    0.5000    1.5000
         0         0         0         0         0
         0         0         0         0         0
\end{verbatim}










